{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: cpu benign-points prefailure-points failure-points total-points\n",
      "File count: 128\n",
      "58192\t50187\t13429\t121808\n",
      "Dataset: buffer-io benign-points prefailure-points failure-points total-points\n",
      "File count: 143\n",
      "369499\t97918\t16274\t483691\n",
      "Dataset: hdd benign-points prefailure-points failure-points total-points\n",
      "File count: 133\n",
      "79345\t74574\t10901\t164820\n",
      "Dataset: oom benign-points prefailure-points failure-points total-points\n",
      "File count: 136\n",
      "96833\t7365\t26196\t130394\n",
      "Dataset: benign benign-points prefailure-points failure-points total-points\n",
      "File count: 151\n",
      "0\t0\t113313\t113313\n",
      "\n",
      "\n",
      "Total files: 691 Total lines:1014026\n"
     ]
    }
   ],
   "source": [
    "total_file_count = 0\n",
    "total_line_count = 0\n",
    "for dataset_name in [\"cpu\", \"buffer-io\", \"hdd\", \"oom\", \"benign\"]:\n",
    "    dataset_dir = f\"./{dataset_name}\"\n",
    "    print(f\"Dataset: {dataset_name} benign-points prefailure-points failure-points total-points\")\n",
    "    file_count = 0\n",
    "    line_count = 0\n",
    "    label_index_tot = 0\n",
    "    failure_index_tot = 0\n",
    "    dataset_metadata = json.load(open(f\"{dataset_dir}/dataset_metadata.json\"))\n",
    "\n",
    "    for datasetFile in os.scandir(dataset_dir):\n",
    "        if not datasetFile.name.endswith(\".csv\"):\n",
    "            continue\n",
    "        file_count += 1\n",
    "        dataset_df = pd.read_csv(datasetFile.path, header=0)\n",
    "        line_count += len(dataset_df)\n",
    "\n",
    "        dataset_file_name = datasetFile.name.split(\".\")[0]\n",
    "        label_index = dataset_metadata[dataset_file_name][\"label_region\"]\n",
    "        failure_index = dataset_metadata[dataset_file_name][\"failure_point\"]\n",
    "        label_index_tot += label_index\n",
    "        failure_index_tot += failure_index\n",
    "    total_file_count += file_count\n",
    "    total_line_count += line_count\n",
    "    print(f\"File count: {file_count}\")\n",
    "    print(f\"{label_index_tot}\\t{failure_index_tot-label_index_tot}\\t{line_count-failure_index_tot}\\t{line_count}\")\n",
    "\n",
    "print(f\"\\n\\nTotal files: {total_file_count} Total lines:{total_line_count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
